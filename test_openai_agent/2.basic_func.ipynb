{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff4b14de-3107-46e9-a410-db07a57b98e5",
   "metadata": {},
   "source": [
    "## OpenAI Agent çš„åŸºç¡€åŠŸèƒ½"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40536444-d5e9-47c4-8149-689122315acf",
   "metadata": {},
   "source": [
    "ä½¿ç”¨ OpenAI Agent çš„ç¬¬ä¸€ä»¶äº‹ï¼šå…³æ‰çƒ¦äººçš„ `tracing`ã€‚\n",
    "\n",
    "> å‚è€ƒ [tracing](https://openai.github.io/openai-agents-python/tracing/) æ–‡æ¡£ï¼šYou can globally disable tracing by setting the env var `OPENAI_AGENTS_DISABLE_TRACING=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba3ae50-eb6a-4478-bc87-fc0c73c794e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_AGENTS_DISABLE_TRACING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29522a35-92d6-44dd-8693-a0877168c0b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:33.878549Z",
     "iopub.status.busy": "2025-05-25T11:20:33.878280Z",
     "iopub.status.idle": "2025-05-25T11:20:33.880901Z",
     "shell.execute_reply": "2025-05-25T11:20:33.880523Z",
     "shell.execute_reply.started": "2025-05-25T11:20:33.878534Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341f70c5-bdda-4a37-b186-5ba8166221be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:20:27.137234Z",
     "iopub.status.busy": "2025-05-24T13:20:27.136871Z",
     "iopub.status.idle": "2025-05-24T13:20:27.147240Z",
     "shell.execute_reply": "2025-05-24T13:20:27.145941Z",
     "shell.execute_reply.started": "2025-05-24T13:20:27.137211Z"
    }
   },
   "source": [
    "**å¯åŠ¨ vllm æœåŠ¡**\n",
    "\n",
    "ç”±äºæˆ‘ä»¬ä½¿ç”¨ vllm å¯åŠ¨ qwen3 æ¨ç†æœåŠ¡ï¼Œä¸”å¸Œæœ›å®ƒæ”¯æŒå·¥å…·è°ƒç”¨ï¼ˆTool Callingï¼‰ï¼Œéœ€è¦å¯¹ vllm å¯åŠ¨å‘½ä»¤è¿›è¡Œé¢å¤–é…ç½®ï¼š\n",
    "\n",
    "```bash\n",
    "--enable-auto-tool-choice \\\n",
    "--tool-call-parser hermes \\\n",
    "```\n",
    "\n",
    "å‚è€ƒï¼š[Tool Calling](https://docs.vllm.ai/en/stable/features/tool_calling.html#qwen-models)\n",
    "\n",
    "å…·ä½“æ¥è¯´ï¼Œä½ éœ€è¦è¿è¡Œå½“å‰ç›®å½•ä¸‹çš„å¯åŠ¨è„šæœ¬ï¼š`bash vllm_server.sh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5dec871-70c3-4b0c-9203-592c4b8e27af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:22:21.663046Z",
     "iopub.status.busy": "2025-05-25T11:22:21.662708Z",
     "iopub.status.idle": "2025-05-25T11:22:21.668419Z",
     "shell.execute_reply": "2025-05-25T11:22:21.667579Z",
     "shell.execute_reply.started": "2025-05-25T11:22:21.663025Z"
    }
   },
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "from agents import (set_default_openai_client, set_default_openai_api,\n",
    "                    Agent, Runner, ModelSettings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cb37c3-aeb7-4e1e-b679-56bee32cc14b",
   "metadata": {},
   "source": [
    "**åˆå§‹åŒ– Agent**\n",
    "\n",
    "ä½¿ç”¨ `Agent()` åˆå§‹åŒ– Agentï¼Œä½¿ç”¨ `Runner` è¿è¡Œ Agentï¼Œ`Runner` æœ‰ä¸‰ç§æ–¹æ³•ï¼š\n",
    "\n",
    "- å¼‚æ­¥ï¼šRunner.run()\n",
    "- åŒæ­¥ï¼šRunner.run_sync()\n",
    "- æµå¼ï¼ˆå¼‚æ­¥ï¼‰ï¼›Runner.run_streamed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "579de414-0bd0-4ddd-99d4-fd65952c5e01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:34.245335Z",
     "iopub.status.busy": "2025-05-25T11:20:34.245249Z",
     "iopub.status.idle": "2025-05-25T11:20:37.463307Z",
     "shell.execute_reply": "2025-05-25T11:20:37.462663Z",
     "shell.execute_reply.started": "2025-05-25T11:20:34.245327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen3æ˜¯é˜¿é‡Œå·´å·´é›†å›¢ç ”å‘çš„ç¬¬ä¸‰ä»£å¤§è¯­è¨€æ¨¡å‹ï¼Œç”±é˜¿é‡Œå·´å·´é›†å›¢ç ”ç©¶é™¢å’Œé˜¿é‡Œå·´å·´äº‘å…±åŒå¼€å‘ï¼Œé¢å‘å¸‚åœºåº”ç”¨ï¼Œå±äºå¤§æ¨¡å‹æŠ€æœ¯çš„å‰æ²¿æ–¹å‘ã€‚ä»¥ä¸‹æ˜¯Qwen3çš„ä¸»è¦ç‰¹ç‚¹å’Œä¼˜åŠ¿ï¼š\n",
      "\n",
      "1. **æ€§èƒ½æå‡**  \n",
      "   Qwen3åœ¨æ€§èƒ½æ–¹é¢ç›¸æ¯”Qwen2æœ‰æ˜¾è‘—æå‡ï¼Œæ”¯æŒæ›´é«˜çš„æ¨ç†é€Ÿåº¦å’Œæ›´å¼ºçš„è®¡ç®—èƒ½åŠ›ï¼Œèƒ½å¤Ÿå¤„ç†æ›´å¤æ‚ã€æ›´åºå¤§çš„æ•°æ®é›†ã€‚\n",
      "\n",
      "2. **åº”ç”¨åœºæ™¯å¹¿æ³›**  \n",
      "   Qwen3é€‚ç”¨äºé‡‘èã€åŒ»ç–—ã€æ•™è‚²ã€å®¢æœç­‰å¤šä¸ªé¢†åŸŸï¼Œèƒ½å¤Ÿæä¾›æ›´ç²¾å‡†çš„æ™ºèƒ½å¯¹è¯ã€æ–‡æœ¬ç”Ÿæˆå’Œå¤šè½®æ¨ç†æœåŠ¡ã€‚\n",
      "\n",
      "3. **å¤šæ¨¡æ€æ”¯æŒ**  \n",
      "   Qwen3æ”¯æŒæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ç­‰å¤šç§è¾“å…¥å½¢å¼ï¼Œèƒ½å¤Ÿå¤„ç†æ›´ä¸°å¯Œçš„äº¤äº’åœºæ™¯ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚\n",
      "\n",
      "4. **æŒç»­ä¼˜åŒ–**  \n",
      "   Qwen3åœ¨ç ”å‘è¿‡ç¨‹ä¸­ä¸æ–­è¿­ä»£ï¼Œç»“åˆæœ€æ–°çš„æŠ€æœ¯ï¼Œå¦‚å¤§è¯­è¨€æ¨¡å‹çš„ä¼˜åŒ–ã€å¤šæ¨¡æ€å¤„ç†èƒ½åŠ›æå‡ï¼Œç¡®ä¿å…¶æŒç»­è¿›æ­¥ã€‚\n",
      "\n",
      "Qwen3çš„æ¨å‡ºæ ‡å¿—ç€å¤§æ¨¡å‹æŠ€æœ¯åœ¨å®é™…åº”ç”¨ä¸­çš„è¿›ä¸€æ­¥æˆç†Ÿï¼Œä¸ºç”¨æˆ·æä¾›æ›´é«˜æ•ˆã€æ™ºèƒ½çš„æœåŠ¡è§£å†³æ–¹æ¡ˆã€‚å¦‚æœæ‚¨æœ‰å…·ä½“åº”ç”¨åœºæ™¯æˆ–æƒ³äº†è§£Qwen3åœ¨æŸä¸ªé¢†åŸŸçš„å…·ä½“è¡¨ç°ï¼Œå¯ä»¥è¿›ä¸€æ­¥æé—®ã€‚\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºè‡ªå®šä¹‰çš„ OpenAI å®¢æˆ·ç«¯\n",
    "custom_client = AsyncOpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    api_key=\"token-kcgyrk\")\n",
    "set_default_openai_client(custom_client)\n",
    "\n",
    "# ä½¿ç”¨ Chat Completions API\n",
    "set_default_openai_api(\"chat_completions\") \n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    instructions=\"You are a helpful assistant\",\n",
    "    model=\"Qwen3-0.6B-FP8\",\n",
    "    model_settings=ModelSettings(\n",
    "        temperature=0.6,\n",
    "        top_p=0.95,\n",
    "    ),\n",
    ")\n",
    "\n",
    "result = await Runner.run(agent, \"ä»‹ç»ä¸€ä¸‹qwen3\")\n",
    "print(result.final_output.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fa57d5-4f9a-4d29-b964-7c3ea0849523",
   "metadata": {},
   "source": [
    "**Function tools**\n",
    "\n",
    "å¯ä»¥å°†ä»»ä½• Python å‡½æ•°ç”¨ä½œå·¥å…·ã€‚å·¥å…·çš„åç§°æ˜¯ Python å‡½æ•°çš„åå­—ï¼›å·¥å…·æè¿°å–è‡ªè¯¥å‡½æ•°çš„ docstringã€‚\n",
    "\n",
    "å‚è€ƒï¼š[Tools](https://openai.github.io/openai-agents-python/tools/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c00bc67-b26b-40c5-b3f8-98900e57556b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:37.464267Z",
     "iopub.status.busy": "2025-05-25T11:20:37.464049Z",
     "iopub.status.idle": "2025-05-25T11:20:37.467673Z",
     "shell.execute_reply": "2025-05-25T11:20:37.466980Z",
     "shell.execute_reply.started": "2025-05-25T11:20:37.464253Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from typing_extensions import TypedDict, Any\n",
    "from agents import FunctionTool, RunContextWrapper, function_tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31359c7-4d92-4404-b2b3-62ecbdbb05e8",
   "metadata": {},
   "source": [
    "æ ¹æ®åŸå¸‚åï¼Œè¿”å›è¯¥åŸå¸‚çš„å¤©æ°”ã€‚\n",
    "\n",
    "```\n",
    "{\n",
    "  \"Beijing\": \"Sunny\",\n",
    "  \"Shanghai\": \"Cloudy\",\n",
    "  \"Guangzhou\": \"Thunderstorm\",\n",
    "  \"Chengdu\": \"Cloudy\",\n",
    "  \"Hangzou\": \"Showery\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b25f640-b416-43d3-9058-73cfa2b321a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:37.468251Z",
     "iopub.status.busy": "2025-05-25T11:20:37.468115Z",
     "iopub.status.idle": "2025-05-25T11:20:37.476673Z",
     "shell.execute_reply": "2025-05-25T11:20:37.476063Z",
     "shell.execute_reply.started": "2025-05-25T11:20:37.468239Z"
    }
   },
   "outputs": [],
   "source": [
    "@function_tool  \n",
    "async def fetch_weather(city: str) -> str:\n",
    "\n",
    "    \"\"\"Fetch the weather for a given city name.\n",
    "\n",
    "    :param city: The city to fetch the weather for (e.g., \"Beijing\").\n",
    "    :return: A string describing the weather (e.g., \"Sunny\", \"Cloudy\").\n",
    "    \"\"\"\n",
    "    # we'd fetch the weather from a weather dict\n",
    "    weather_dict = {\n",
    "      \"Beijing\": \"Sunny\",\n",
    "      \"Shanghai\": \"Cloudy\",\n",
    "      \"Guangzhou\": \"Thunderstorm\",\n",
    "      \"Chengdu\": \"Cloudy\",\n",
    "      \"Hangzou\": \"Showery\"\n",
    "    }\n",
    "    return weather_dict.get(city, \"Unknown\")\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    instructions=\"You are a helpful assistant\",\n",
    "    model=\"Qwen3-0.6B-FP8\",\n",
    "    model_settings=ModelSettings(\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "    ),\n",
    "    tools=[fetch_weather],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ac2460f-456a-40b1-b6cb-bc6c05bdd512",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:37.477528Z",
     "iopub.status.busy": "2025-05-25T11:20:37.477268Z",
     "iopub.status.idle": "2025-05-25T11:20:48.826648Z",
     "shell.execute_reply": "2025-05-25T11:20:48.826059Z",
     "shell.execute_reply.started": "2025-05-25T11:20:37.477514Z"
    }
   },
   "outputs": [],
   "source": [
    "citys = ['Beijing', 'Shanghai', 'Guangzhou', 'Chengdu', 'Hangzou', 'Shenzhen']\n",
    "\n",
    "res = []\n",
    "for city in citys:\n",
    "    result = await Runner.run(agent, f\"Tell me the weather in {city}.\")\n",
    "    res.append(result.final_output.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "897a331d-cf56-48d5-97ab-b3386d9eb73f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:48.827295Z",
     "iopub.status.busy": "2025-05-25T11:20:48.827125Z",
     "iopub.status.idle": "2025-05-25T11:20:48.830771Z",
     "shell.execute_reply": "2025-05-25T11:20:48.830096Z",
     "shell.execute_reply.started": "2025-05-25T11:20:48.827279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in Beijing is sunny. Let me know if you need more details!\n",
      "The weather in Shanghai is **Cloudy**. Let me know if you need more details! ğŸŒ¤ï¸\n",
      "The weather in Guangzhou is currently a **thunderstorm**.\n",
      "The weather in Chengdu is **Cloudy**.\n",
      "The weather in Hangzou is Showery. Let me know if you need further details!\n",
      "I don't have access to real-time weather data for Shenzhen. Could you please verify the city name again? If it's spelled correctly, I'll try to fetch it for you.\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08226b20-517d-4ecb-ad99-7768ceef5045",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T12:22:24.782617Z",
     "iopub.status.busy": "2025-05-24T12:22:24.781320Z",
     "iopub.status.idle": "2025-05-24T12:22:24.791317Z",
     "shell.execute_reply": "2025-05-24T12:22:24.789476Z",
     "shell.execute_reply.started": "2025-05-24T12:22:24.782588Z"
    }
   },
   "source": [
    "> é¡ºä¾¿ä¸€æï¼ŒOpenAI è¿˜æä¾›äº†ä¸€äº›å†…ç½®å·¥å…·ï¼ˆHosted toolsï¼‰ï¼Œæ¯”å¦‚ï¼š\n",
    "> \n",
    "> - `WebSearchTool`: ç½‘ç»œæœç´¢\n",
    "> - `CodeInterpreterTool`: åœ¨æ²™ç›’ç¯å¢ƒæ‰§è¡Œä»£ç \n",
    "> - `HostedMCPTool`: è°ƒç”¨è¿œç¨‹ MCP æœåŠ¡\n",
    "> - `LocalShellTool`: åœ¨æœ¬åœ°æœºå™¨ä¸Šè¿è¡Œ Shell å‘½ä»¤\n",
    "> \n",
    "> ä½†æ˜¯ `Chat Completions API` æ¨¡å¼ä¸‹æ— æ³•ä½¿ç”¨ä»¥ä¸ŠåŠŸèƒ½ï¼Œæˆ‘ä»¬å½“å‰æ­£å¤„äºè¯¥æ¨¡å¼ã€‚\n",
    "\n",
    "OpenAI æä¾›ä¸¤ç§é£æ ¼çš„ API æ¥å£ï¼š\n",
    "\n",
    "- `OpenAIResponsesModel`: ä½¿ç”¨æœ€æ–°çš„ [Responses API](https://platform.openai.com/docs/api-reference/responses)ï¼Œå³ `/v1/responses`\n",
    "- `OpenAIChatCompletionsModel`: ä½¿ç”¨æ—§çš„ [Chat Completions API](https://platform.openai.com/docs/api-reference/chat)ï¼Œå³ `/v1/chat/completions`\n",
    "\n",
    "ç”±äº vLLM å½“å‰é»˜è®¤æ”¯æŒæ—§çš„ `Chat Completions API` æ¥å£ï¼Œè€Œ OpenAI Agent é»˜è®¤æ”¯æŒæ–°æ¥å£ï¼Œå› æ­¤æ—¶å¸¸å­˜åœ¨ä¸€äº›æ— æ³•å…¼å®¹çš„æƒ…å†µã€‚å‚è€ƒï¼š[models](https://openai.github.io/openai-agents-python/models/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ee6acc-9bcf-4133-add8-6f30c29fe92a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:37:31.630342Z",
     "iopub.status.busy": "2025-05-24T13:37:31.629866Z",
     "iopub.status.idle": "2025-05-24T13:37:31.637909Z",
     "shell.execute_reply": "2025-05-24T13:37:31.636765Z",
     "shell.execute_reply.started": "2025-05-24T13:37:31.630296Z"
    }
   },
   "source": [
    "**MCP**\n",
    "\n",
    "MCP æ˜¯ä¸€ç§ä¸º LLM æä¾›å·¥å…·å’Œä¸Šä¸‹æ–‡çš„æ–¹æ³•ã€‚OpenAI Agent æä¾›äº†ä¸‰ç§æ–¹æ³•è¿æ¥ MCP æœåŠ¡ï¼š\n",
    "\n",
    "- `stdio`: ä½œä¸ºåº”ç”¨ç¨‹åºçš„å­ç¨‹åºè¿è¡Œï¼Œå¯ä»¥å°†å®ƒè§†ä¸ºâ€œæœ¬åœ°â€è¿è¡Œ\n",
    "- `HTTP over SSE`: è¿œç¨‹è¿è¡Œ MCP Serversï¼Œå¯ä»¥é€šè¿‡ URL è¿æ¥å®ƒä»¬\n",
    "- `Streamable HTTP`: ä½¿ç”¨ MCP ä¸­å®šä¹‰çš„ Streamable HTTP è¿œç¨‹è¿è¡Œ\n",
    "\n",
    "\n",
    "\n",
    "å‚è€ƒï¼š\n",
    "\n",
    "- doc: [mcp](https://openai.github.io/openai-agents-python/mcp/)\n",
    "- example: [filesystem_example/main.py](https://github.com/openai/openai-agents-python/blob/main/examples/mcp/filesystem_example/main.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be229232-8e9d-46f8-846b-e3a303381c67",
   "metadata": {},
   "source": [
    "ä¸‹é¢æˆ‘ä»¬ç”¨ **SSE** çš„æ–¹æ³•è¿æ¥ MCP\n",
    "\n",
    "é¦–å…ˆå¯åŠ¨ `FastMCP` æœåŠ¡ï¼Œåœ¨å½“å‰ç›®å½•ä¸‹æ‰“å¼€ terminalï¼š\n",
    "\n",
    "```bash\n",
    "cd sse_example\n",
    "python server.py\n",
    "```\n",
    "\n",
    "å¦‚æœæˆåŠŸè¿è¡Œï¼Œå‘½ä»¤è¡Œè¾“å‡ºå¦‚ä¸‹ï¼š\n",
    "\n",
    "```bash\n",
    "$ python server.py \n",
    "INFO:     Started server process [27849]\n",
    "INFO:     Waiting for application startup.\n",
    "INFO:     Application startup complete.\n",
    "INFO:     Uvicorn running on http://0.0.0.0:8866 (Press CTRL+C to quit)\n",
    "```\n",
    "\n",
    "ç„¶åè¿è¡Œ Agent ä½œä¸ºå®¢æˆ·ç«¯ï¼Œè°ƒç”¨åˆšåˆšå¯åŠ¨çš„ `FastMCP` æœåŠ¡ï¼š\n",
    "\n",
    "```bash\n",
    "python main.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cba3421b-c3f6-4bbc-bd67-7111007d25ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:48.831543Z",
     "iopub.status.busy": "2025-05-25T11:20:48.831359Z",
     "iopub.status.idle": "2025-05-25T11:20:48.839440Z",
     "shell.execute_reply": "2025-05-25T11:20:48.838874Z",
     "shell.execute_reply.started": "2025-05-25T11:20:48.831529Z"
    }
   },
   "outputs": [],
   "source": [
    "from agents.mcp import MCPServer, MCPServerSse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79b32d51-8730-4f0e-94a1-21d13b29f8e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:48.840158Z",
     "iopub.status.busy": "2025-05-25T11:20:48.840015Z",
     "iopub.status.idle": "2025-05-25T11:20:50.765466Z",
     "shell.execute_reply": "2025-05-25T11:20:50.765089Z",
     "shell.execute_reply.started": "2025-05-25T11:20:48.840148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Math result: \n",
      "\n",
      "The result of adding 17 and 6 is 23.\n",
      "Secret word: \n",
      "\n",
      "The secret word is **cherry**.\n"
     ]
    }
   ],
   "source": [
    "async def quick_test():\n",
    "    async with MCPServerSse(\n",
    "        name=\"SSE Python Server\",\n",
    "        params={\"url\": \"http://localhost:8866/sse\"},\n",
    "    ) as server:\n",
    "        custom_client = AsyncOpenAI(\n",
    "            base_url=\"http://localhost:8000/v1\",\n",
    "            api_key=\"token-kcgyrk\"\n",
    "        )\n",
    "        set_default_openai_client(custom_client)\n",
    "        set_default_openai_api(\"chat_completions\")\n",
    "\n",
    "        agent = Agent(\n",
    "            name=\"Assistant\",\n",
    "            instructions=\"Use the tools to answer the questions.\",\n",
    "            model=\"Qwen3-0.6B-FP8\",\n",
    "            mcp_servers=[server],\n",
    "            model_settings=ModelSettings(\n",
    "                temperature=0.6,\n",
    "                top_p=0.9,\n",
    "                tool_choice=\"required\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # æµ‹è¯•è®¡ç®—\n",
    "        result = await Runner.run(starting_agent=agent, input=\"Add 17 and 6\")\n",
    "        print(f\"Math result: {result.final_output}\")\n",
    "\n",
    "        # æµ‹è¯•ç§˜å¯†è¯\n",
    "        result = await Runner.run(starting_agent=agent, input=\"What's the secret word?\")\n",
    "        print(f\"Secret word: {result.final_output}\")\n",
    "\n",
    "await quick_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b655529d-a837-4e77-923a-4a90ffe7616f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T07:13:37.152818Z",
     "iopub.status.busy": "2025-05-25T07:13:37.152476Z",
     "iopub.status.idle": "2025-05-25T07:13:37.161643Z",
     "shell.execute_reply": "2025-05-25T07:13:37.160131Z",
     "shell.execute_reply.started": "2025-05-25T07:13:37.152797Z"
    }
   },
   "source": [
    "ä½¿ç”¨ `inspect` è·å–ç±» `MCPServerStdio` çš„æ„é€ å‡½æ•°çš„å‚æ•°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a258c77c-d787-409c-a937-3420cb669efe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:50.766233Z",
     "iopub.status.busy": "2025-05-25T11:20:50.765907Z",
     "iopub.status.idle": "2025-05-25T11:20:50.769272Z",
     "shell.execute_reply": "2025-05-25T11:20:50.768899Z",
     "shell.execute_reply.started": "2025-05-25T11:20:50.766220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ„é€ å‡½æ•°å‚æ•°:\n",
      "  - params: 'MCPServerSseParams'\n",
      "  - cache_tools_list: 'bool' = False\n",
      "  - name: 'str | None' = None\n",
      "  - client_session_timeout_seconds: 'float | None' = 5\n",
      "\n",
      "æºä»£ç ä½ç½®: /home/canva/miniconda3/lib/python3.12/site-packages/agents/mcp/server.py\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "sig = inspect.signature(MCPServerSse.__init__)\n",
    "\n",
    "# è·å–å‚æ•°é»˜è®¤å€¼\n",
    "print(\"æ„é€ å‡½æ•°å‚æ•°:\")\n",
    "for param_name, param in sig.parameters.items():\n",
    "    if param_name != 'self':\n",
    "        print(f\"  - {param}\")\n",
    "\n",
    "print(f\"\\næºä»£ç ä½ç½®: {inspect.getfile(MCPServerSse)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7977d6-d595-48aa-88fc-f813f1045af2",
   "metadata": {},
   "source": [
    "**Handoffs**\n",
    "\n",
    "Handoffsï¼ˆäº¤æ¥ï¼‰å…è®¸ Agent å°†ä»»åŠ¡å§”æ‰˜ç»™å¦ä¸€ä¸ª Agentã€‚è¿™åœ¨ä¸åŒ Agent é€‚ç”¨äºä¸åŒé¢†åŸŸçš„æƒ…å†µä¸‹ç‰¹åˆ«æœ‰ç”¨ã€‚å°¤å…¶å¯¹äºæµç¨‹ç±»çš„æœåŠ¡ç‰¹åˆ«æœ‰ç”¨ï¼Œæ¯”å¦‚æŸä¸ª Agent å¤„ç†é€€æ¬¾ç¨‹åºï¼Œå®ƒå…ˆä¿®æ”¹è®¢å•çŠ¶æ€å¹¶æ‰§è¡Œé€€æ¬¾ï¼Œç„¶åä¼ é€’ç»™ä¸‹ä¸€ä¸ª Agent ç»™ç”¨æˆ·å‘é€é€€æ¬¾é€šçŸ¥ï¼Œå¹¶å›å¤å®¢æˆ·æ¥ä¸‹æ¥çš„æé—®ã€‚\n",
    "\n",
    "Agent çš„ handoffs å‚æ•°ï¼Œæ—¢å¯ä»¥æ¥å— Agentï¼Œä¹Ÿå¯ä»¥æ¥å—è‡ªå®šä¹‰çš„ Handoff å¯¹è±¡ã€‚\n",
    "\n",
    "å‚è€ƒï¼š\n",
    "\n",
    "- doc: [handoffs](https://openai.github.io/openai-agents-python/handoffs/)\n",
    "- example: [message_filter.py](https://github.com/openai/openai-agents-python/blob/main/examples/handoffs/message_filter.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c137de30-3a0e-4a80-9b60-cf5a3a222c62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:50.770018Z",
     "iopub.status.busy": "2025-05-25T11:20:50.769629Z",
     "iopub.status.idle": "2025-05-25T11:20:50.775935Z",
     "shell.execute_reply": "2025-05-25T11:20:50.775536Z",
     "shell.execute_reply.started": "2025-05-25T11:20:50.770006Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import random\n",
    "\n",
    "from openai import AsyncOpenAI\n",
    "from agents import (Agent, HandoffInputData, Runner, function_tool, handoff, trace,\n",
    "                    set_default_openai_client, set_default_openai_api, ModelSettings)\n",
    "from agents.extensions import handoff_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c367d70c-5cbc-400e-820c-910da781f060",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:50.776409Z",
     "iopub.status.busy": "2025-05-25T11:20:50.776312Z",
     "iopub.status.idle": "2025-05-25T11:20:50.795323Z",
     "shell.execute_reply": "2025-05-25T11:20:50.794678Z",
     "shell.execute_reply.started": "2025-05-25T11:20:50.776401Z"
    }
   },
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def random_number_tool(max: int) -> int:\n",
    "    \"\"\"Return a random integer between 0 and the given maximum.\"\"\"\n",
    "    return random.randint(0, max)\n",
    "\n",
    "\n",
    "def chinese_handoff_message_filter(handoff_message_data: HandoffInputData) -> HandoffInputData:\n",
    "    # First, we'll remove any tool-related messages from the message history\n",
    "    handoff_message_data = handoff_filters.remove_all_tools(handoff_message_data)\n",
    "\n",
    "    # Second, we'll also remove the first two items from the history, just for demonstration\n",
    "    history = (\n",
    "        tuple(handoff_message_data.input_history[2:])\n",
    "        if isinstance(handoff_message_data.input_history, tuple)\n",
    "        else handoff_message_data.input_history\n",
    "    )\n",
    "\n",
    "    return HandoffInputData(\n",
    "        input_history=history,\n",
    "        pre_handoff_items=tuple(handoff_message_data.pre_handoff_items),\n",
    "        new_items=tuple(handoff_message_data.new_items),\n",
    "    )\n",
    "\n",
    "\n",
    "# åˆ›å»ºè‡ªå®šä¹‰çš„ OpenAI å®¢æˆ·ç«¯\n",
    "custom_client = AsyncOpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    api_key=\"token-kcgyrk\")\n",
    "set_default_openai_client(custom_client)\n",
    "set_default_openai_api(\"chat_completions\")\n",
    "\n",
    "\n",
    "first_agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    model=\"Qwen3-0.6B-FP8\",\n",
    "    instructions=\"Be extremely concise.\",\n",
    "    tools=[random_number_tool],\n",
    ")\n",
    "\n",
    "chinese_agent = Agent(\n",
    "    name=\"Chinese Assistant\",\n",
    "    model=\"Qwen3-0.6B-FP8\",\n",
    "    instructions=\"You only speak Chinese and are extremely concise.\",\n",
    "    handoff_description=\"A Chinese-speaking assistant.\",\n",
    ")\n",
    "\n",
    "second_agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    model=\"Qwen3-0.6B-FP8\",\n",
    "    instructions=(\n",
    "        \"Be a helpful assistant. If the user speaks Chinese, handoff to the Chinese assistant.\"\n",
    "    ),\n",
    "    handoffs=[handoff(chinese_agent, input_filter=chinese_handoff_message_filter)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abc7466a-bd02-4464-8851-69fb39deceff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:22:08.401837Z",
     "iopub.status.busy": "2025-05-25T11:22:08.400698Z",
     "iopub.status.idle": "2025-05-25T11:22:14.106637Z",
     "shell.execute_reply": "2025-05-25T11:22:14.106211Z",
     "shell.execute_reply.started": "2025-05-25T11:22:08.401805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 1 done]\n",
      "Hello, Sora! How can I assist you today?\n",
      "\n",
      "[Step 2 done]\n",
      "The random number between 0 and 100 is **78**. Let me know if you need anything else! ğŸ˜Š\n",
      "\n",
      "[Step 3 done]\n",
      "The population of New York City is approximately **8,440,000** as of the latest estimates. Let me know if you need help with anything else! ğŸ˜Š\n",
      "\n",
      "[Step 4 done]\n",
      "æˆ‘çš„åå­—æ˜¯ Soraï¼Œæˆ‘ä½åœ¨ç¾å›½çº½çº¦å¸‚ã€‚\n"
     ]
    }
   ],
   "source": [
    "# 1. Send a regular message to the first agent\n",
    "result = await Runner.run(first_agent, input=\"Hi, my name is Sora.\")\n",
    "print(\"[Step 1 done]\")\n",
    "print(result.final_output.strip())\n",
    "\n",
    "# 2. Ask it to generate a number\n",
    "result = await Runner.run(\n",
    "    first_agent,\n",
    "    input=result.to_input_list()\n",
    "    + [{\"content\": \"Can you generate a random number between 0 and 100?\", \"role\": \"user\"}],\n",
    ")\n",
    "print(\"\\n[Step 2 done]\")\n",
    "print(result.final_output.strip())\n",
    "\n",
    "# 3. Call the second agent\n",
    "result = await Runner.run(\n",
    "    second_agent,\n",
    "    input=result.to_input_list()\n",
    "    + [\n",
    "        {\n",
    "            \"content\": \"I live in New York City. Whats the population of the city?\",\n",
    "            \"role\": \"user\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(\"\\n[Step 3 done]\")\n",
    "print(result.final_output.strip())\n",
    "\n",
    "# 4. Cause a handoff to occur\n",
    "result = await Runner.run(\n",
    "    second_agent,\n",
    "    input=result.to_input_list()\n",
    "    + [\n",
    "        {\n",
    "            \"content\": \"æˆ‘çš„åå­—æ˜¯ä»€ä¹ˆï¼Œæˆ‘ä½åœ¨å“ªé‡Œï¼Ÿ\",\n",
    "            \"role\": \"user\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(\"\\n[Step 4 done]\")\n",
    "print(result.final_output.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5ece51-704f-48f9-a148-a88fd1d35958",
   "metadata": {},
   "source": [
    "**Central Agent**\n",
    "\n",
    "åœ¨æŸäº›å·¥ä½œæµä¸­ï¼Œä½ å¯èƒ½å¸Œæœ›é€šè¿‡ä¸€ä¸ªä¸­å¿ƒ Agent ç¼–æ’ç½‘ç»œï¼Œè€Œéé€šè¿‡ Handoffs ç§»äº¤æ§åˆ¶æƒã€‚\n",
    "\n",
    "å‚è€ƒï¼š[agents-as-tools](https://openai.github.io/openai-agents-python/tools/#agents-as-tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3ecb12d-b3b5-4208-9803-33db531734ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:21:35.957350Z",
     "iopub.status.busy": "2025-05-25T11:21:35.955757Z",
     "iopub.status.idle": "2025-05-25T11:21:35.987435Z",
     "shell.execute_reply": "2025-05-25T11:21:35.986840Z",
     "shell.execute_reply.started": "2025-05-25T11:21:35.957317Z"
    }
   },
   "outputs": [],
   "source": [
    "# åˆ›å»ºè‡ªå®šä¹‰çš„ OpenAI å®¢æˆ·ç«¯\n",
    "custom_client = AsyncOpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    api_key=\"token-kcgyrk\")\n",
    "set_default_openai_client(custom_client)\n",
    "set_default_openai_api(\"chat_completions\")\n",
    "\n",
    "spanish_agent = Agent(\n",
    "    name=\"Spanish agent\",\n",
    "    instructions=\"You translate the user's message to Spanish\",\n",
    "    model=\"Qwen3-0.6B-FP8\",\n",
    ")\n",
    "\n",
    "chinese_agent = Agent(\n",
    "    name=\"Chinese agent\",\n",
    "    instructions=\"You translate the user's message to Chinese\",\n",
    "    model=\"Qwen3-0.6B-FP8\",\n",
    ")\n",
    "\n",
    "orchestrator_agent = Agent(\n",
    "    name=\"orchestrator_agent\",\n",
    "    instructions=(\n",
    "        \"You are a translation agent. You use the tools given to you to translate.\"\n",
    "        \"If asked for multiple translations, you call the relevant tools.\"\n",
    "    ),\n",
    "    model=\"Qwen3-0.6B-FP8\",\n",
    "    tools=[\n",
    "        spanish_agent.as_tool(\n",
    "            tool_name=\"translate_to_spanish\",\n",
    "            tool_description=\"Translate the user's message to Spanish\",\n",
    "        ),\n",
    "        chinese_agent.as_tool(\n",
    "            tool_name=\"translate_to_chinese\",\n",
    "            tool_description=\"Translate the user's message to Chinese\",\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "119efc5b-d07b-4219-8d7f-a950de4f7946",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:21:36.409742Z",
     "iopub.status.busy": "2025-05-25T11:21:36.408700Z",
     "iopub.status.idle": "2025-05-25T11:21:39.333058Z",
     "shell.execute_reply": "2025-05-25T11:21:39.332591Z",
     "shell.execute_reply.started": "2025-05-25T11:21:36.409711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‚¨å¥½ï¼Œæ€ä¹ˆæ ·å—ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "result = await Runner.run(orchestrator_agent, input=\"Say 'Hello, how are you?' in Chinese.\")\n",
    "print(result.final_output.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbae836-809f-4db5-b1fc-722233725473",
   "metadata": {},
   "source": [
    "**Guardrails**\n",
    "\n",
    "Guardrailsï¼ˆæŠ¤æ ï¼‰æ˜¯ Agent çš„ä¸€ç§é˜²æŠ¤æœºåˆ¶ï¼Œç”¨äºæ£€æµ‹ç”¨æˆ·è¾“å…¥ï¼Œä»¥é˜²ç”¨æˆ·æ‰§è¡Œä¸€äº›éå¸¸è§„æ“ä½œï¼Œæ¯”å¦‚æ‰§è¡Œ 100 æ¬¡ Search APIï¼Œè¿™å¯èƒ½å¯¼è‡´èµ„æŸã€‚\n",
    "\n",
    "æŠ¤æ æœ‰ä¸¤ç§ï¼š\n",
    "- è¾“å…¥æŠ¤æ  `Input guardrails`\n",
    "- è¾“å‡ºæŠ¤æ  `Output guardrails`\n",
    "\n",
    "å‚è€ƒï¼š[guardrails](https://openai.github.io/openai-agents-python/guardrails/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1c2ae2-f91d-4ffd-aee3-a909293a0da9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
