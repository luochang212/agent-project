{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff4b14de-3107-46e9-a410-db07a57b98e5",
   "metadata": {},
   "source": [
    "## OpenAI Agent 的基础功能"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40536444-d5e9-47c4-8149-689122315acf",
   "metadata": {},
   "source": [
    "使用 OpenAI Agent 的第一件事：关掉烦人的 `tracing`。\n",
    "\n",
    "> 参考 [tracing](https://openai.github.io/openai-agents-python/tracing/) 文档：You can globally disable tracing by setting the env var `OPENAI_AGENTS_DISABLE_TRACING=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba3ae50-eb6a-4478-bc87-fc0c73c794e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_AGENTS_DISABLE_TRACING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29522a35-92d6-44dd-8693-a0877168c0b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:33.878549Z",
     "iopub.status.busy": "2025-05-25T11:20:33.878280Z",
     "iopub.status.idle": "2025-05-25T11:20:33.880901Z",
     "shell.execute_reply": "2025-05-25T11:20:33.880523Z",
     "shell.execute_reply.started": "2025-05-25T11:20:33.878534Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341f70c5-bdda-4a37-b186-5ba8166221be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:20:27.137234Z",
     "iopub.status.busy": "2025-05-24T13:20:27.136871Z",
     "iopub.status.idle": "2025-05-24T13:20:27.147240Z",
     "shell.execute_reply": "2025-05-24T13:20:27.145941Z",
     "shell.execute_reply.started": "2025-05-24T13:20:27.137211Z"
    }
   },
   "source": [
    "**启动 vllm 服务**\n",
    "\n",
    "由于我们使用 vllm 启动 qwen3 推理服务，且希望它支持工具调用（Tool Calling），需要对 vllm 启动命令进行额外配置：\n",
    "\n",
    "```bash\n",
    "--enable-auto-tool-choice \\\n",
    "--tool-call-parser hermes \\\n",
    "```\n",
    "\n",
    "参考：[Tool Calling](https://docs.vllm.ai/en/stable/features/tool_calling.html#qwen-models)\n",
    "\n",
    "具体来说，你需要运行当前目录下的启动脚本：`bash vllm_server.sh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5dec871-70c3-4b0c-9203-592c4b8e27af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:22:21.663046Z",
     "iopub.status.busy": "2025-05-25T11:22:21.662708Z",
     "iopub.status.idle": "2025-05-25T11:22:21.668419Z",
     "shell.execute_reply": "2025-05-25T11:22:21.667579Z",
     "shell.execute_reply.started": "2025-05-25T11:22:21.663025Z"
    }
   },
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "from agents import (set_default_openai_client, set_default_openai_api,\n",
    "                    Agent, Runner, ModelSettings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cb37c3-aeb7-4e1e-b679-56bee32cc14b",
   "metadata": {},
   "source": [
    "**初始化 Agent**\n",
    "\n",
    "使用 `Agent()` 初始化 Agent，使用 `Runner` 运行 Agent，`Runner` 有三种方法：\n",
    "\n",
    "- 异步：Runner.run()\n",
    "- 同步：Runner.run_sync()\n",
    "- 流式（异步）；Runner.run_streamed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "579de414-0bd0-4ddd-99d4-fd65952c5e01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:34.245335Z",
     "iopub.status.busy": "2025-05-25T11:20:34.245249Z",
     "iopub.status.idle": "2025-05-25T11:20:37.463307Z",
     "shell.execute_reply": "2025-05-25T11:20:37.462663Z",
     "shell.execute_reply.started": "2025-05-25T11:20:34.245327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen3是阿里巴巴集团研发的第三代大语言模型，由阿里巴巴集团研究院和阿里巴巴云共同开发，面向市场应用，属于大模型技术的前沿方向。以下是Qwen3的主要特点和优势：\n",
      "\n",
      "1. **性能提升**  \n",
      "   Qwen3在性能方面相比Qwen2有显著提升，支持更高的推理速度和更强的计算能力，能够处理更复杂、更庞大的数据集。\n",
      "\n",
      "2. **应用场景广泛**  \n",
      "   Qwen3适用于金融、医疗、教育、客服等多个领域，能够提供更精准的智能对话、文本生成和多轮推理服务。\n",
      "\n",
      "3. **多模态支持**  \n",
      "   Qwen3支持文本、图像、音频等多种输入形式，能够处理更丰富的交互场景，提升用户体验。\n",
      "\n",
      "4. **持续优化**  \n",
      "   Qwen3在研发过程中不断迭代，结合最新的技术，如大语言模型的优化、多模态处理能力提升，确保其持续进步。\n",
      "\n",
      "Qwen3的推出标志着大模型技术在实际应用中的进一步成熟，为用户提供更高效、智能的服务解决方案。如果您有具体应用场景或想了解Qwen3在某个领域的具体表现，可以进一步提问。\n"
     ]
    }
   ],
   "source": [
    "# 创建自定义的 OpenAI 客户端\n",
    "custom_client = AsyncOpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    api_key=\"token-kcgyrk\")\n",
    "set_default_openai_client(custom_client)\n",
    "\n",
    "# 使用 Chat Completions API\n",
    "set_default_openai_api(\"chat_completions\") \n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    instructions=\"You are a helpful assistant\",\n",
    "    model=\"Qwen3-0.6B-FP8\",\n",
    "    model_settings=ModelSettings(\n",
    "        temperature=0.6,\n",
    "        top_p=0.95,\n",
    "    ),\n",
    ")\n",
    "\n",
    "result = await Runner.run(agent, \"介绍一下qwen3\")\n",
    "print(result.final_output.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fa57d5-4f9a-4d29-b964-7c3ea0849523",
   "metadata": {},
   "source": [
    "**Function tools**\n",
    "\n",
    "可以将任何 Python 函数用作工具。工具的名称是 Python 函数的名字；工具描述取自该函数的 docstring。\n",
    "\n",
    "参考：[Tools](https://openai.github.io/openai-agents-python/tools/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c00bc67-b26b-40c5-b3f8-98900e57556b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:37.464267Z",
     "iopub.status.busy": "2025-05-25T11:20:37.464049Z",
     "iopub.status.idle": "2025-05-25T11:20:37.467673Z",
     "shell.execute_reply": "2025-05-25T11:20:37.466980Z",
     "shell.execute_reply.started": "2025-05-25T11:20:37.464253Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from typing_extensions import TypedDict, Any\n",
    "from agents import FunctionTool, RunContextWrapper, function_tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31359c7-4d92-4404-b2b3-62ecbdbb05e8",
   "metadata": {},
   "source": [
    "根据城市名，返回该城市的天气。\n",
    "\n",
    "```\n",
    "{\n",
    "  \"Beijing\": \"Sunny\",\n",
    "  \"Shanghai\": \"Cloudy\",\n",
    "  \"Guangzhou\": \"Thunderstorm\",\n",
    "  \"Chengdu\": \"Cloudy\",\n",
    "  \"Hangzou\": \"Showery\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b25f640-b416-43d3-9058-73cfa2b321a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:37.468251Z",
     "iopub.status.busy": "2025-05-25T11:20:37.468115Z",
     "iopub.status.idle": "2025-05-25T11:20:37.476673Z",
     "shell.execute_reply": "2025-05-25T11:20:37.476063Z",
     "shell.execute_reply.started": "2025-05-25T11:20:37.468239Z"
    }
   },
   "outputs": [],
   "source": [
    "@function_tool  \n",
    "async def fetch_weather(city: str) -> str:\n",
    "\n",
    "    \"\"\"Fetch the weather for a given city name.\n",
    "\n",
    "    :param city: The city to fetch the weather for (e.g., \"Beijing\").\n",
    "    :return: A string describing the weather (e.g., \"Sunny\", \"Cloudy\").\n",
    "    \"\"\"\n",
    "    # we'd fetch the weather from a weather dict\n",
    "    weather_dict = {\n",
    "      \"Beijing\": \"Sunny\",\n",
    "      \"Shanghai\": \"Cloudy\",\n",
    "      \"Guangzhou\": \"Thunderstorm\",\n",
    "      \"Chengdu\": \"Cloudy\",\n",
    "      \"Hangzou\": \"Showery\"\n",
    "    }\n",
    "    return weather_dict.get(city, \"Unknown\")\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    instructions=\"You are a helpful assistant\",\n",
    "    model=\"Qwen3-0.6B-FP8\",\n",
    "    model_settings=ModelSettings(\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "    ),\n",
    "    tools=[fetch_weather],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ac2460f-456a-40b1-b6cb-bc6c05bdd512",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:37.477528Z",
     "iopub.status.busy": "2025-05-25T11:20:37.477268Z",
     "iopub.status.idle": "2025-05-25T11:20:48.826648Z",
     "shell.execute_reply": "2025-05-25T11:20:48.826059Z",
     "shell.execute_reply.started": "2025-05-25T11:20:37.477514Z"
    }
   },
   "outputs": [],
   "source": [
    "citys = ['Beijing', 'Shanghai', 'Guangzhou', 'Chengdu', 'Hangzou', 'Shenzhen']\n",
    "\n",
    "res = []\n",
    "for city in citys:\n",
    "    result = await Runner.run(agent, f\"Tell me the weather in {city}.\")\n",
    "    res.append(result.final_output.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "897a331d-cf56-48d5-97ab-b3386d9eb73f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:48.827295Z",
     "iopub.status.busy": "2025-05-25T11:20:48.827125Z",
     "iopub.status.idle": "2025-05-25T11:20:48.830771Z",
     "shell.execute_reply": "2025-05-25T11:20:48.830096Z",
     "shell.execute_reply.started": "2025-05-25T11:20:48.827279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in Beijing is sunny. Let me know if you need more details!\n",
      "The weather in Shanghai is **Cloudy**. Let me know if you need more details! 🌤️\n",
      "The weather in Guangzhou is currently a **thunderstorm**.\n",
      "The weather in Chengdu is **Cloudy**.\n",
      "The weather in Hangzou is Showery. Let me know if you need further details!\n",
      "I don't have access to real-time weather data for Shenzhen. Could you please verify the city name again? If it's spelled correctly, I'll try to fetch it for you.\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08226b20-517d-4ecb-ad99-7768ceef5045",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T12:22:24.782617Z",
     "iopub.status.busy": "2025-05-24T12:22:24.781320Z",
     "iopub.status.idle": "2025-05-24T12:22:24.791317Z",
     "shell.execute_reply": "2025-05-24T12:22:24.789476Z",
     "shell.execute_reply.started": "2025-05-24T12:22:24.782588Z"
    }
   },
   "source": [
    "> 顺便一提，OpenAI 还提供了一些内置工具（Hosted tools），比如：\n",
    "> \n",
    "> - `WebSearchTool`: 网络搜索\n",
    "> - `CodeInterpreterTool`: 在沙盒环境执行代码\n",
    "> - `HostedMCPTool`: 调用远程 MCP 服务\n",
    "> - `LocalShellTool`: 在本地机器上运行 Shell 命令\n",
    "> \n",
    "> 但是 `Chat Completions API` 模式下无法使用以上功能，我们当前正处于该模式。\n",
    "\n",
    "OpenAI 提供两种风格的 API 接口：\n",
    "\n",
    "- `OpenAIResponsesModel`: 使用最新的 [Responses API](https://platform.openai.com/docs/api-reference/responses)，即 `/v1/responses`\n",
    "- `OpenAIChatCompletionsModel`: 使用旧的 [Chat Completions API](https://platform.openai.com/docs/api-reference/chat)，即 `/v1/chat/completions`\n",
    "\n",
    "由于 vLLM 当前默认支持旧的 `Chat Completions API` 接口，而 OpenAI Agent 默认支持新接口，因此时常存在一些无法兼容的情况。参考：[models](https://openai.github.io/openai-agents-python/models/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ee6acc-9bcf-4133-add8-6f30c29fe92a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:37:31.630342Z",
     "iopub.status.busy": "2025-05-24T13:37:31.629866Z",
     "iopub.status.idle": "2025-05-24T13:37:31.637909Z",
     "shell.execute_reply": "2025-05-24T13:37:31.636765Z",
     "shell.execute_reply.started": "2025-05-24T13:37:31.630296Z"
    }
   },
   "source": [
    "**MCP**\n",
    "\n",
    "MCP 是一种为 LLM 提供工具和上下文的方法。OpenAI Agent 提供了三种方法连接 MCP 服务：\n",
    "\n",
    "- `stdio`: 作为应用程序的子程序运行，可以将它视为“本地”运行\n",
    "- `HTTP over SSE`: 远程运行 MCP Servers，可以通过 URL 连接它们\n",
    "- `Streamable HTTP`: 使用 MCP 中定义的 Streamable HTTP 远程运行\n",
    "\n",
    "\n",
    "\n",
    "参考：\n",
    "\n",
    "- doc: [mcp](https://openai.github.io/openai-agents-python/mcp/)\n",
    "- example: [filesystem_example/main.py](https://github.com/openai/openai-agents-python/blob/main/examples/mcp/filesystem_example/main.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be229232-8e9d-46f8-846b-e3a303381c67",
   "metadata": {},
   "source": [
    "下面我们用 **SSE** 的方法连接 MCP\n",
    "\n",
    "首先启动 `FastMCP` 服务，在当前目录下打开 terminal：\n",
    "\n",
    "```bash\n",
    "cd sse_example\n",
    "python server.py\n",
    "```\n",
    "\n",
    "如果成功运行，命令行输出如下：\n",
    "\n",
    "```bash\n",
    "$ python server.py \n",
    "INFO:     Started server process [27849]\n",
    "INFO:     Waiting for application startup.\n",
    "INFO:     Application startup complete.\n",
    "INFO:     Uvicorn running on http://0.0.0.0:8866 (Press CTRL+C to quit)\n",
    "```\n",
    "\n",
    "然后运行 Agent 作为客户端，调用刚刚启动的 `FastMCP` 服务：\n",
    "\n",
    "```bash\n",
    "python main.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cba3421b-c3f6-4bbc-bd67-7111007d25ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:48.831543Z",
     "iopub.status.busy": "2025-05-25T11:20:48.831359Z",
     "iopub.status.idle": "2025-05-25T11:20:48.839440Z",
     "shell.execute_reply": "2025-05-25T11:20:48.838874Z",
     "shell.execute_reply.started": "2025-05-25T11:20:48.831529Z"
    }
   },
   "outputs": [],
   "source": [
    "from agents.mcp import MCPServer, MCPServerSse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79b32d51-8730-4f0e-94a1-21d13b29f8e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:48.840158Z",
     "iopub.status.busy": "2025-05-25T11:20:48.840015Z",
     "iopub.status.idle": "2025-05-25T11:20:50.765466Z",
     "shell.execute_reply": "2025-05-25T11:20:50.765089Z",
     "shell.execute_reply.started": "2025-05-25T11:20:48.840148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Math result: \n",
      "\n",
      "The result of adding 17 and 6 is 23.\n",
      "Secret word: \n",
      "\n",
      "The secret word is **cherry**.\n"
     ]
    }
   ],
   "source": [
    "async def quick_test():\n",
    "    async with MCPServerSse(\n",
    "        name=\"SSE Python Server\",\n",
    "        params={\"url\": \"http://localhost:8866/sse\"},\n",
    "    ) as server:\n",
    "        custom_client = AsyncOpenAI(\n",
    "            base_url=\"http://localhost:8000/v1\",\n",
    "            api_key=\"token-kcgyrk\"\n",
    "        )\n",
    "        set_default_openai_client(custom_client)\n",
    "        set_default_openai_api(\"chat_completions\")\n",
    "\n",
    "        agent = Agent(\n",
    "            name=\"Assistant\",\n",
    "            instructions=\"Use the tools to answer the questions.\",\n",
    "            model=\"Qwen3-0.6B-FP8\",\n",
    "            mcp_servers=[server],\n",
    "            model_settings=ModelSettings(\n",
    "                temperature=0.6,\n",
    "                top_p=0.9,\n",
    "                tool_choice=\"required\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # 测试计算\n",
    "        result = await Runner.run(starting_agent=agent, input=\"Add 17 and 6\")\n",
    "        print(f\"Math result: {result.final_output}\")\n",
    "\n",
    "        # 测试秘密词\n",
    "        result = await Runner.run(starting_agent=agent, input=\"What's the secret word?\")\n",
    "        print(f\"Secret word: {result.final_output}\")\n",
    "\n",
    "await quick_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b655529d-a837-4e77-923a-4a90ffe7616f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T07:13:37.152818Z",
     "iopub.status.busy": "2025-05-25T07:13:37.152476Z",
     "iopub.status.idle": "2025-05-25T07:13:37.161643Z",
     "shell.execute_reply": "2025-05-25T07:13:37.160131Z",
     "shell.execute_reply.started": "2025-05-25T07:13:37.152797Z"
    }
   },
   "source": [
    "使用 `inspect` 获取类 `MCPServerStdio` 的构造函数的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a258c77c-d787-409c-a937-3420cb669efe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:50.766233Z",
     "iopub.status.busy": "2025-05-25T11:20:50.765907Z",
     "iopub.status.idle": "2025-05-25T11:20:50.769272Z",
     "shell.execute_reply": "2025-05-25T11:20:50.768899Z",
     "shell.execute_reply.started": "2025-05-25T11:20:50.766220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "构造函数参数:\n",
      "  - params: 'MCPServerSseParams'\n",
      "  - cache_tools_list: 'bool' = False\n",
      "  - name: 'str | None' = None\n",
      "  - client_session_timeout_seconds: 'float | None' = 5\n",
      "\n",
      "源代码位置: /home/canva/miniconda3/lib/python3.12/site-packages/agents/mcp/server.py\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "sig = inspect.signature(MCPServerSse.__init__)\n",
    "\n",
    "# 获取参数默认值\n",
    "print(\"构造函数参数:\")\n",
    "for param_name, param in sig.parameters.items():\n",
    "    if param_name != 'self':\n",
    "        print(f\"  - {param}\")\n",
    "\n",
    "print(f\"\\n源代码位置: {inspect.getfile(MCPServerSse)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7977d6-d595-48aa-88fc-f813f1045af2",
   "metadata": {},
   "source": [
    "**Handoffs**\n",
    "\n",
    "Handoffs（交接）允许 Agent 将任务委托给另一个 Agent。这在不同 Agent 适用于不同领域的情况下特别有用。尤其对于流程类的服务特别有用，比如某个 Agent 处理退款程序，它先修改订单状态并执行退款，然后传递给下一个 Agent 给用户发送退款通知，并回复客户接下来的提问。\n",
    "\n",
    "Agent 的 handoffs 参数，既可以接受 Agent，也可以接受自定义的 Handoff 对象。\n",
    "\n",
    "参考：\n",
    "\n",
    "- doc: [handoffs](https://openai.github.io/openai-agents-python/handoffs/)\n",
    "- example: [message_filter.py](https://github.com/openai/openai-agents-python/blob/main/examples/handoffs/message_filter.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c137de30-3a0e-4a80-9b60-cf5a3a222c62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:50.770018Z",
     "iopub.status.busy": "2025-05-25T11:20:50.769629Z",
     "iopub.status.idle": "2025-05-25T11:20:50.775935Z",
     "shell.execute_reply": "2025-05-25T11:20:50.775536Z",
     "shell.execute_reply.started": "2025-05-25T11:20:50.770006Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import random\n",
    "\n",
    "from openai import AsyncOpenAI\n",
    "from agents import (Agent, HandoffInputData, Runner, function_tool, handoff, trace,\n",
    "                    set_default_openai_client, set_default_openai_api, ModelSettings)\n",
    "from agents.extensions import handoff_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c367d70c-5cbc-400e-820c-910da781f060",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:20:50.776409Z",
     "iopub.status.busy": "2025-05-25T11:20:50.776312Z",
     "iopub.status.idle": "2025-05-25T11:20:50.795323Z",
     "shell.execute_reply": "2025-05-25T11:20:50.794678Z",
     "shell.execute_reply.started": "2025-05-25T11:20:50.776401Z"
    }
   },
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def random_number_tool(max: int) -> int:\n",
    "    \"\"\"Return a random integer between 0 and the given maximum.\"\"\"\n",
    "    return random.randint(0, max)\n",
    "\n",
    "\n",
    "def chinese_handoff_message_filter(handoff_message_data: HandoffInputData) -> HandoffInputData:\n",
    "    # First, we'll remove any tool-related messages from the message history\n",
    "    handoff_message_data = handoff_filters.remove_all_tools(handoff_message_data)\n",
    "\n",
    "    # Second, we'll also remove the first two items from the history, just for demonstration\n",
    "    history = (\n",
    "        tuple(handoff_message_data.input_history[2:])\n",
    "        if isinstance(handoff_message_data.input_history, tuple)\n",
    "        else handoff_message_data.input_history\n",
    "    )\n",
    "\n",
    "    return HandoffInputData(\n",
    "        input_history=history,\n",
    "        pre_handoff_items=tuple(handoff_message_data.pre_handoff_items),\n",
    "        new_items=tuple(handoff_message_data.new_items),\n",
    "    )\n",
    "\n",
    "\n",
    "# 创建自定义的 OpenAI 客户端\n",
    "custom_client = AsyncOpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    api_key=\"token-kcgyrk\")\n",
    "set_default_openai_client(custom_client)\n",
    "set_default_openai_api(\"chat_completions\")\n",
    "\n",
    "\n",
    "first_agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    model=\"Qwen3-0.6B-FP8\",\n",
    "    instructions=\"Be extremely concise.\",\n",
    "    tools=[random_number_tool],\n",
    ")\n",
    "\n",
    "chinese_agent = Agent(\n",
    "    name=\"Chinese Assistant\",\n",
    "    model=\"Qwen3-0.6B-FP8\",\n",
    "    instructions=\"You only speak Chinese and are extremely concise.\",\n",
    "    handoff_description=\"A Chinese-speaking assistant.\",\n",
    ")\n",
    "\n",
    "second_agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    model=\"Qwen3-0.6B-FP8\",\n",
    "    instructions=(\n",
    "        \"Be a helpful assistant. If the user speaks Chinese, handoff to the Chinese assistant.\"\n",
    "    ),\n",
    "    handoffs=[handoff(chinese_agent, input_filter=chinese_handoff_message_filter)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abc7466a-bd02-4464-8851-69fb39deceff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:22:08.401837Z",
     "iopub.status.busy": "2025-05-25T11:22:08.400698Z",
     "iopub.status.idle": "2025-05-25T11:22:14.106637Z",
     "shell.execute_reply": "2025-05-25T11:22:14.106211Z",
     "shell.execute_reply.started": "2025-05-25T11:22:08.401805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 1 done]\n",
      "Hello, Sora! How can I assist you today?\n",
      "\n",
      "[Step 2 done]\n",
      "The random number between 0 and 100 is **78**. Let me know if you need anything else! 😊\n",
      "\n",
      "[Step 3 done]\n",
      "The population of New York City is approximately **8,440,000** as of the latest estimates. Let me know if you need help with anything else! 😊\n",
      "\n",
      "[Step 4 done]\n",
      "我的名字是 Sora，我住在美国纽约市。\n"
     ]
    }
   ],
   "source": [
    "# 1. Send a regular message to the first agent\n",
    "result = await Runner.run(first_agent, input=\"Hi, my name is Sora.\")\n",
    "print(\"[Step 1 done]\")\n",
    "print(result.final_output.strip())\n",
    "\n",
    "# 2. Ask it to generate a number\n",
    "result = await Runner.run(\n",
    "    first_agent,\n",
    "    input=result.to_input_list()\n",
    "    + [{\"content\": \"Can you generate a random number between 0 and 100?\", \"role\": \"user\"}],\n",
    ")\n",
    "print(\"\\n[Step 2 done]\")\n",
    "print(result.final_output.strip())\n",
    "\n",
    "# 3. Call the second agent\n",
    "result = await Runner.run(\n",
    "    second_agent,\n",
    "    input=result.to_input_list()\n",
    "    + [\n",
    "        {\n",
    "            \"content\": \"I live in New York City. Whats the population of the city?\",\n",
    "            \"role\": \"user\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(\"\\n[Step 3 done]\")\n",
    "print(result.final_output.strip())\n",
    "\n",
    "# 4. Cause a handoff to occur\n",
    "result = await Runner.run(\n",
    "    second_agent,\n",
    "    input=result.to_input_list()\n",
    "    + [\n",
    "        {\n",
    "            \"content\": \"我的名字是什么，我住在哪里？\",\n",
    "            \"role\": \"user\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(\"\\n[Step 4 done]\")\n",
    "print(result.final_output.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5ece51-704f-48f9-a148-a88fd1d35958",
   "metadata": {},
   "source": [
    "**Central Agent**\n",
    "\n",
    "在某些工作流中，你可能希望通过一个中心 Agent 编排网络，而非通过 Handoffs 移交控制权。\n",
    "\n",
    "参考：[agents-as-tools](https://openai.github.io/openai-agents-python/tools/#agents-as-tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3ecb12d-b3b5-4208-9803-33db531734ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:21:35.957350Z",
     "iopub.status.busy": "2025-05-25T11:21:35.955757Z",
     "iopub.status.idle": "2025-05-25T11:21:35.987435Z",
     "shell.execute_reply": "2025-05-25T11:21:35.986840Z",
     "shell.execute_reply.started": "2025-05-25T11:21:35.957317Z"
    }
   },
   "outputs": [],
   "source": [
    "# 创建自定义的 OpenAI 客户端\n",
    "custom_client = AsyncOpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    api_key=\"token-kcgyrk\")\n",
    "set_default_openai_client(custom_client)\n",
    "set_default_openai_api(\"chat_completions\")\n",
    "\n",
    "spanish_agent = Agent(\n",
    "    name=\"Spanish agent\",\n",
    "    instructions=\"You translate the user's message to Spanish\",\n",
    "    model=\"Qwen3-0.6B-FP8\",\n",
    ")\n",
    "\n",
    "chinese_agent = Agent(\n",
    "    name=\"Chinese agent\",\n",
    "    instructions=\"You translate the user's message to Chinese\",\n",
    "    model=\"Qwen3-0.6B-FP8\",\n",
    ")\n",
    "\n",
    "orchestrator_agent = Agent(\n",
    "    name=\"orchestrator_agent\",\n",
    "    instructions=(\n",
    "        \"You are a translation agent. You use the tools given to you to translate.\"\n",
    "        \"If asked for multiple translations, you call the relevant tools.\"\n",
    "    ),\n",
    "    model=\"Qwen3-0.6B-FP8\",\n",
    "    tools=[\n",
    "        spanish_agent.as_tool(\n",
    "            tool_name=\"translate_to_spanish\",\n",
    "            tool_description=\"Translate the user's message to Spanish\",\n",
    "        ),\n",
    "        chinese_agent.as_tool(\n",
    "            tool_name=\"translate_to_chinese\",\n",
    "            tool_description=\"Translate the user's message to Chinese\",\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "119efc5b-d07b-4219-8d7f-a950de4f7946",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T11:21:36.409742Z",
     "iopub.status.busy": "2025-05-25T11:21:36.408700Z",
     "iopub.status.idle": "2025-05-25T11:21:39.333058Z",
     "shell.execute_reply": "2025-05-25T11:21:39.332591Z",
     "shell.execute_reply.started": "2025-05-25T11:21:36.409711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "您好，怎么样吗？\n"
     ]
    }
   ],
   "source": [
    "result = await Runner.run(orchestrator_agent, input=\"Say 'Hello, how are you?' in Chinese.\")\n",
    "print(result.final_output.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbae836-809f-4db5-b1fc-722233725473",
   "metadata": {},
   "source": [
    "**Guardrails**\n",
    "\n",
    "Guardrails（护栏）是 Agent 的一种防护机制，用于检测用户输入，以防用户执行一些非常规操作，比如执行 100 次 Search API，这可能导致资损。\n",
    "\n",
    "护栏有两种：\n",
    "- 输入护栏 `Input guardrails`\n",
    "- 输出护栏 `Output guardrails`\n",
    "\n",
    "参考：[guardrails](https://openai.github.io/openai-agents-python/guardrails/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1c2ae2-f91d-4ffd-aee3-a909293a0da9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
