{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f543eb41-3193-4ddb-9fe4-f92d2cffb442",
   "metadata": {},
   "source": [
    "## Qwen3-4B-FP8 模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9d9d0df-67c7-43b7-8177-314acbc43d74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T09:10:12.480099Z",
     "iopub.status.busy": "2025-04-30T09:10:12.479140Z",
     "iopub.status.idle": "2025-04-30T09:10:12.484608Z",
     "shell.execute_reply": "2025-04-30T09:10:12.483545Z",
     "shell.execute_reply.started": "2025-04-30T09:10:12.480063Z"
    }
   },
   "outputs": [],
   "source": [
    "# !uv pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef377359-1bf7-4c41-8684-d6082f478821",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T09:10:12.485757Z",
     "iopub.status.busy": "2025-04-30T09:10:12.485530Z",
     "iopub.status.idle": "2025-04-30T09:10:17.809203Z",
     "shell.execute_reply": "2025-04-30T09:10:17.808664Z",
     "shell.execute_reply.started": "2025-04-30T09:10:12.485738Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# 下载 Qwen/Qwen3-4B-FP8 模型，并从本地路径加载\n",
    "MODEL_PATH = '../model/Qwen/Qwen3-4B-FP8'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb5a58d-7edb-4062-b88b-ad9cde3a2dbe",
   "metadata": {},
   "source": [
    "加载 `tokenizer` 和 `model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edf33593-4024-4033-8c91-72d7c37342f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T09:10:17.810069Z",
     "iopub.status.busy": "2025-04-30T09:10:17.809842Z",
     "iopub.status.idle": "2025-04-30T09:15:29.496565Z",
     "shell.execute_reply": "2025-04-30T09:15:29.494516Z",
     "shell.execute_reply.started": "2025-04-30T09:10:17.810056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823abc19586947528fb52cafebed768d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "print(f'model.device: {model.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56a27f3-37ab-414e-a1ea-9ab2ca552b36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T08:14:42.781977Z",
     "iopub.status.busy": "2025-04-29T08:14:42.781416Z",
     "iopub.status.idle": "2025-04-29T08:14:42.792974Z",
     "shell.execute_reply": "2025-04-29T08:14:42.791246Z",
     "shell.execute_reply.started": "2025-04-29T08:14:42.781952Z"
    }
   },
   "source": [
    "通过 `tokenizer.apply_chat_template()` 对 `messages` 应用 Qwen3 聊天模板 `chat template`，将 `messages` 转成 Qwen3 模型认识的格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35191fb7-3e0e-4e3d-9cfb-54ea4f56af3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T09:15:29.498311Z",
     "iopub.status.busy": "2025-04-30T09:15:29.497534Z",
     "iopub.status.idle": "2025-04-30T09:15:29.534794Z",
     "shell.execute_reply": "2025-04-30T09:15:29.534057Z",
     "shell.execute_reply.started": "2025-04-30T09:15:29.498283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_inputs.keys(): dict_keys(['input_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "# prepare the model input\n",
    "prompt = \"目前比较主流的rag技术都有哪些\"\n",
    "\n",
    "# ChatML 格式，参考 https://docs.unsloth.ai/basics/datasets-guide#formatting-the-data\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=True # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\n",
    "\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "print(f'model_inputs.keys(): {model_inputs.keys()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649b2a0f-3031-42f3-9947-9acd7c2d3fd7",
   "metadata": {},
   "source": [
    "Qwen3 进行文本生成 (completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7707a3b-e552-4e15-8991-7bc562e03f61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T09:15:29.535785Z",
     "iopub.status.busy": "2025-04-30T09:15:29.535476Z",
     "iopub.status.idle": "2025-04-30T09:15:29.539452Z",
     "shell.execute_reply": "2025-04-30T09:15:29.538453Z",
     "shell.execute_reply.started": "2025-04-30T09:15:29.535767Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.generate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "785055d0-c9ec-48cd-a598-1d2fbef334c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T09:15:29.540950Z",
     "iopub.status.busy": "2025-04-30T09:15:29.540734Z",
     "iopub.status.idle": "2025-04-30T09:17:07.176929Z",
     "shell.execute_reply": "2025-04-30T09:17:07.176277Z",
     "shell.execute_reply.started": "2025-04-30T09:15:29.540935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(output_ids): 888\n"
     ]
    }
   ],
   "source": [
    "# conduct text completion\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=32768,\n",
    "    temperature=0.6,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.5\n",
    ")\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
    "print(f'len(output_ids): {len(output_ids)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5002198-2dbc-4053-b9f7-b8d9637db3a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T09:17:07.177560Z",
     "iopub.status.busy": "2025-04-30T09:17:07.177404Z",
     "iopub.status.idle": "2025-04-30T09:17:07.181760Z",
     "shell.execute_reply": "2025-04-30T09:17:07.180982Z",
     "shell.execute_reply.started": "2025-04-30T09:17:07.177548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 200\n"
     ]
    }
   ],
   "source": [
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "print(f'index: {index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad81b89f-60f4-41fd-ae81-98681f35b9c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T09:17:07.183067Z",
     "iopub.status.busy": "2025-04-30T09:17:07.182340Z",
     "iopub.status.idle": "2025-04-30T09:17:07.191544Z",
     "shell.execute_reply": "2025-04-30T09:17:07.190330Z",
     "shell.execute_reply.started": "2025-04-30T09:17:07.183047Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "think_content: <think>\n",
      "嗯，用户问的是现在市面上有哪些比较流行的RAG（Retrieval-Augmented Generation）技术和方法。首先我得回忆一下自己学过的相关知识。\n",
      "\n",
      "记得以前在学习NLP的时候提到过一些基于检索增强生成的方法，在大模型中应用广泛吧？比如像DPR、T5这些可能属于基础框架？\n",
      "\n",
      "然后还有各种不同的架构设计和优化策略呢！比如说多阶段召回系统或者混合搜索方式之类的扩展方案吗？\n",
      "再想想最近有没有什么新的进展或变种形式出现啦～例如结合图神经网络进行更复杂的语义理解处理的情况也有听说哦！\n",
      "\n",
      "另外还需要考虑不同应用场景下的选择差异性问题：是偏向于文档级别的信息整合还是需要跨模态的信息融合能力嘛～\n",
      "\n",
      "对了还应该区分出开源实现与商业解决方案之间的区别，并且给出每个类型代表性的例子以及它们各自的特点优势所在。\n",
      "这样整理下来就能形成一个结构清晰的回答给用户提供参考价值了吧~\n",
      "</think>\n",
      "answer_content: 当前业界广泛应用并持续演进的主要 **Relevance-Augmented Retrieval (RR)** 技术及其衍生方向可以分为以下几个核心类别：\n",
      "\n",
      "---\n",
      "\n",
      "### 一、**传统 RAG 基础范式**\n",
      "1. **Document-Level Retriever + Generator 架构**\n",
      "\n",
      "   - 核心组件：\n",
      "     ```python\n",
      "      # 检索器: DPR(Dense Passage Ranking)\n",
      "       retriever = DensePassageRanking()\n",
      "       \n",
      "        generator= T5ForConditionalGeneration() \n",
      "         query=\"如何提高工作效率?\"\n",
      "          docs=retriever(query)  \n",
      "           response_generator(generator,docs)\n",
      "\n",
      "    ```\n",
      "   \n",
      "20世纪末到今早年间的典型流程包括三个步骤:\n",
      "- 文本预训练(如BERT等Transformer系列);\n",
      "- 索引构建(BM25/FAISS/Lucene etc.);\n",
      "- 排序算法(SLAM/PQ/TensorFlow Serving).\n",
      "\n",
      "> *注意:* 此类体系主要面向单一文本源场景.\n",
      "\n",
      "---\n",
      "## \n",
      "\n",
      "二、「智能体」型 RR 扩展形态\n",
      "    \n",
      "3️⃣ 多级组合模式(Multi-stage Recall System):\n",
      "```mermaid\n",
      "graph LR    \n",
      "A[Query] --> B{是否需领域适配?}\n",
      "B-->|否|RagBase\n",
      "C[Rerank+FAQ]\n",
      "```\n",
      "\n",
      "4️⃣ 图谱化推理(Graph-based Reasoning): 如Neo4j节点嵌入配合GNN层做复杂关系建模.\n",
      "        \n",
      "6️⃣ 跨语言支持(Cross-LINGual Search):\n",
      "\n",
      "使用m-BERT/Multilingual RoFormer作为特征提取模块,\n",
      "\n",
      "7️⃣ 视觉辅助(Vision Transformer for Multi-modal Data), 可用于视频摘要抽取任务.\n",
      "\n",
      "\n",
      "三、“自适应”动态调整机制\n",
      "                \n",
      "8️⃣ 自动调节参数范围(Auto-tuning Range Control),\n",
      "9️⃣ 动作规划链(Action Planning Chain),\n",
      "\n",
      "四，“可解释”的交互反馈循环\n",
      "                        \n",
      "10 🧠 非监督强化学习(Relational Reinforcement Learning)，通过奖励函数引导对话路径,\n",
      "  \n",
      "\n",
      "五 “元认知”\n",
      "11 ⛳ 元记忆(metamemory)-based learning，\n",
      "  \n",
      "  \n",
      "六 \"联邦\"协同计算(Federated Computation)\n",
      "\n",
      "\n",
      "七“微服务云原生”\n",
      "\n",
      "八：“边缘端部署”，适用于IoT设备上的轻量化版本\n",
      "\n",
      "\n",
      "九：\"数字孪生\"\n",
      "十:\"模拟仿真\"\n",
      "\n",
      "十一.\"因果推断\"\n",
      "\n",
      "\n",
      "十二.“时空感知”: 对时间序列数据具有敏感度,\n",
      "\n",
      "\n",
      "十三.”社交属性\": 包含话题热度追踪等功能,\n",
      "\n",
      "\n",
      "\n",
      "十四。”伦理合规控制”, 引入道德约束条件;\n",
      "\n",
      "\n",
      "十五.’隐私保护’,”差分私有加密\";\n",
      "\n",
      "\n",
      "十六.'区块链存证';\n",
      "\n",
      "\n",
      "\n",
      "十七．'量子机器学习';\n",
      "\n",
      "\n",
      "\n",
      "十八.'\"脑机接口\"' ;\n",
      "\n",
      "\n",
      "十九.\"'沉浸感体验'\"；\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "二十\".虚拟现实环境中的自然交流\".\n",
      "\n",
      "\n",
      "\n",
      "这种分类标准下可以看到,RAG 已经从最初的简单问答工具发展为涵盖多个学科领域的综合性AI平台生态系统.\n",
      "\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "总结来说:\n",
      "\n",
      "* 当前最前沿的技术路线主要包括以下六大发展方向*\n",
      "1. 再次强调上述各点内容;\n",
      "2. 提供实际案例说明每项创新的应用效果;\n",
      "\n",
      "因此建议读者根据自身需求灵活选用合适的方式开展研究工作! ✏️📚🚀\n"
     ]
    }
   ],
   "source": [
    "think_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "answer_content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"think_content:\", think_content)\n",
    "print(\"answer_content:\", answer_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695c993d-0bc9-4498-8367-204b45c0124b",
   "metadata": {},
   "source": [
    "参考：\n",
    "\n",
    "- Huggingface: [Qwen/Qwen3-4B-FP8](https://huggingface.co/Qwen/Qwen3-4B-FP8)\n",
    "- Qwen blog: [Qwen3: Think Deeper, Act Faster](https://qwenlm.github.io/blog/qwen3/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614bf86a-0baf-466f-a04b-a5586b291f89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
