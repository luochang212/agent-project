{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f543eb41-3193-4ddb-9fe4-f92d2cffb442",
   "metadata": {},
   "source": [
    "## Qwen3-4B-FP8 æ¨¡å‹æ¨ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9d9d0df-67c7-43b7-8177-314acbc43d74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T09:10:12.480099Z",
     "iopub.status.busy": "2025-04-30T09:10:12.479140Z",
     "iopub.status.idle": "2025-04-30T09:10:12.484608Z",
     "shell.execute_reply": "2025-04-30T09:10:12.483545Z",
     "shell.execute_reply.started": "2025-04-30T09:10:12.480063Z"
    }
   },
   "outputs": [],
   "source": [
    "# !uv pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef377359-1bf7-4c41-8684-d6082f478821",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T09:10:12.485757Z",
     "iopub.status.busy": "2025-04-30T09:10:12.485530Z",
     "iopub.status.idle": "2025-04-30T09:10:17.809203Z",
     "shell.execute_reply": "2025-04-30T09:10:17.808664Z",
     "shell.execute_reply.started": "2025-04-30T09:10:12.485738Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# ä¸‹è½½ Qwen/Qwen3-4B-FP8 æ¨¡å‹ï¼Œå¹¶ä»æœ¬åœ°è·¯å¾„åŠ è½½\n",
    "MODEL_PATH = '../model/Qwen/Qwen3-4B-FP8'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb5a58d-7edb-4062-b88b-ad9cde3a2dbe",
   "metadata": {},
   "source": [
    "åŠ è½½ `tokenizer` å’Œ `model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edf33593-4024-4033-8c91-72d7c37342f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T09:10:17.810069Z",
     "iopub.status.busy": "2025-04-30T09:10:17.809842Z",
     "iopub.status.idle": "2025-04-30T09:15:29.496565Z",
     "shell.execute_reply": "2025-04-30T09:15:29.494516Z",
     "shell.execute_reply.started": "2025-04-30T09:10:17.810056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823abc19586947528fb52cafebed768d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "print(f'model.device: {model.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56a27f3-37ab-414e-a1ea-9ab2ca552b36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T08:14:42.781977Z",
     "iopub.status.busy": "2025-04-29T08:14:42.781416Z",
     "iopub.status.idle": "2025-04-29T08:14:42.792974Z",
     "shell.execute_reply": "2025-04-29T08:14:42.791246Z",
     "shell.execute_reply.started": "2025-04-29T08:14:42.781952Z"
    }
   },
   "source": [
    "é€šè¿‡ `tokenizer.apply_chat_template()` å¯¹ `messages` åº”ç”¨ Qwen3 èŠå¤©æ¨¡æ¿ `chat template`ï¼Œå°† `messages` è½¬æˆ Qwen3 æ¨¡å‹è®¤è¯†çš„æ ¼å¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35191fb7-3e0e-4e3d-9cfb-54ea4f56af3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T09:15:29.498311Z",
     "iopub.status.busy": "2025-04-30T09:15:29.497534Z",
     "iopub.status.idle": "2025-04-30T09:15:29.534794Z",
     "shell.execute_reply": "2025-04-30T09:15:29.534057Z",
     "shell.execute_reply.started": "2025-04-30T09:15:29.498283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_inputs.keys(): dict_keys(['input_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "# prepare the model input\n",
    "prompt = \"ç›®å‰æ¯”è¾ƒä¸»æµçš„ragæŠ€æœ¯éƒ½æœ‰å“ªäº›\"\n",
    "\n",
    "# ChatML æ ¼å¼ï¼Œå‚è€ƒ https://docs.unsloth.ai/basics/datasets-guide#formatting-the-data\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=True # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\n",
    "\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "print(f'model_inputs.keys(): {model_inputs.keys()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649b2a0f-3031-42f3-9947-9acd7c2d3fd7",
   "metadata": {},
   "source": [
    "Qwen3 è¿›è¡Œæ–‡æœ¬ç”Ÿæˆ (completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7707a3b-e552-4e15-8991-7bc562e03f61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T09:15:29.535785Z",
     "iopub.status.busy": "2025-04-30T09:15:29.535476Z",
     "iopub.status.idle": "2025-04-30T09:15:29.539452Z",
     "shell.execute_reply": "2025-04-30T09:15:29.538453Z",
     "shell.execute_reply.started": "2025-04-30T09:15:29.535767Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.generate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "785055d0-c9ec-48cd-a598-1d2fbef334c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T09:15:29.540950Z",
     "iopub.status.busy": "2025-04-30T09:15:29.540734Z",
     "iopub.status.idle": "2025-04-30T09:17:07.176929Z",
     "shell.execute_reply": "2025-04-30T09:17:07.176277Z",
     "shell.execute_reply.started": "2025-04-30T09:15:29.540935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(output_ids): 888\n"
     ]
    }
   ],
   "source": [
    "# conduct text completion\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=32768,\n",
    "    temperature=0.6,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.5\n",
    ")\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
    "print(f'len(output_ids): {len(output_ids)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5002198-2dbc-4053-b9f7-b8d9637db3a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T09:17:07.177560Z",
     "iopub.status.busy": "2025-04-30T09:17:07.177404Z",
     "iopub.status.idle": "2025-04-30T09:17:07.181760Z",
     "shell.execute_reply": "2025-04-30T09:17:07.180982Z",
     "shell.execute_reply.started": "2025-04-30T09:17:07.177548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 200\n"
     ]
    }
   ],
   "source": [
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "print(f'index: {index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad81b89f-60f4-41fd-ae81-98681f35b9c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T09:17:07.183067Z",
     "iopub.status.busy": "2025-04-30T09:17:07.182340Z",
     "iopub.status.idle": "2025-04-30T09:17:07.191544Z",
     "shell.execute_reply": "2025-04-30T09:17:07.190330Z",
     "shell.execute_reply.started": "2025-04-30T09:17:07.183047Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "think_content: <think>\n",
      "å—¯ï¼Œç”¨æˆ·é—®çš„æ˜¯ç°åœ¨å¸‚é¢ä¸Šæœ‰å“ªäº›æ¯”è¾ƒæµè¡Œçš„RAGï¼ˆRetrieval-Augmented Generationï¼‰æŠ€æœ¯å’Œæ–¹æ³•ã€‚é¦–å…ˆæˆ‘å¾—å›å¿†ä¸€ä¸‹è‡ªå·±å­¦è¿‡çš„ç›¸å…³çŸ¥è¯†ã€‚\n",
      "\n",
      "è®°å¾—ä»¥å‰åœ¨å­¦ä¹ NLPçš„æ—¶å€™æåˆ°è¿‡ä¸€äº›åŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆçš„æ–¹æ³•ï¼Œåœ¨å¤§æ¨¡å‹ä¸­åº”ç”¨å¹¿æ³›å§ï¼Ÿæ¯”å¦‚åƒDPRã€T5è¿™äº›å¯èƒ½å±äºåŸºç¡€æ¡†æ¶ï¼Ÿ\n",
      "\n",
      "ç„¶åè¿˜æœ‰å„ç§ä¸åŒçš„æ¶æ„è®¾è®¡å’Œä¼˜åŒ–ç­–ç•¥å‘¢ï¼æ¯”å¦‚è¯´å¤šé˜¶æ®µå¬å›ç³»ç»Ÿæˆ–è€…æ··åˆæœç´¢æ–¹å¼ä¹‹ç±»çš„æ‰©å±•æ–¹æ¡ˆå—ï¼Ÿ\n",
      "å†æƒ³æƒ³æœ€è¿‘æœ‰æ²¡æœ‰ä»€ä¹ˆæ–°çš„è¿›å±•æˆ–å˜ç§å½¢å¼å‡ºç°å•¦ï½ä¾‹å¦‚ç»“åˆå›¾ç¥ç»ç½‘ç»œè¿›è¡Œæ›´å¤æ‚çš„è¯­ä¹‰ç†è§£å¤„ç†çš„æƒ…å†µä¹Ÿæœ‰å¬è¯´å“¦ï¼\n",
      "\n",
      "å¦å¤–è¿˜éœ€è¦è€ƒè™‘ä¸åŒåº”ç”¨åœºæ™¯ä¸‹çš„é€‰æ‹©å·®å¼‚æ€§é—®é¢˜ï¼šæ˜¯åå‘äºæ–‡æ¡£çº§åˆ«çš„ä¿¡æ¯æ•´åˆè¿˜æ˜¯éœ€è¦è·¨æ¨¡æ€çš„ä¿¡æ¯èåˆèƒ½åŠ›å˜›ï½\n",
      "\n",
      "å¯¹äº†è¿˜åº”è¯¥åŒºåˆ†å‡ºå¼€æºå®ç°ä¸å•†ä¸šè§£å†³æ–¹æ¡ˆä¹‹é—´çš„åŒºåˆ«ï¼Œå¹¶ä¸”ç»™å‡ºæ¯ä¸ªç±»å‹ä»£è¡¨æ€§çš„ä¾‹å­ä»¥åŠå®ƒä»¬å„è‡ªçš„ç‰¹ç‚¹ä¼˜åŠ¿æ‰€åœ¨ã€‚\n",
      "è¿™æ ·æ•´ç†ä¸‹æ¥å°±èƒ½å½¢æˆä¸€ä¸ªç»“æ„æ¸…æ™°çš„å›ç­”ç»™ç”¨æˆ·æä¾›å‚è€ƒä»·å€¼äº†å§~\n",
      "</think>\n",
      "answer_content: å½“å‰ä¸šç•Œå¹¿æ³›åº”ç”¨å¹¶æŒç»­æ¼”è¿›çš„ä¸»è¦ **Relevance-Augmented Retrieval (RR)** æŠ€æœ¯åŠå…¶è¡ç”Ÿæ–¹å‘å¯ä»¥åˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªæ ¸å¿ƒç±»åˆ«ï¼š\n",
      "\n",
      "---\n",
      "\n",
      "### ä¸€ã€**ä¼ ç»Ÿ RAG åŸºç¡€èŒƒå¼**\n",
      "1. **Document-Level Retriever + Generator æ¶æ„**\n",
      "\n",
      "   - æ ¸å¿ƒç»„ä»¶ï¼š\n",
      "     ```python\n",
      "      # æ£€ç´¢å™¨: DPR(Dense Passage Ranking)\n",
      "       retriever = DensePassageRanking()\n",
      "       \n",
      "        generator= T5ForConditionalGeneration() \n",
      "         query=\"å¦‚ä½•æé«˜å·¥ä½œæ•ˆç‡?\"\n",
      "          docs=retriever(query)  \n",
      "           response_generator(generator,docs)\n",
      "\n",
      "    ```\n",
      "   \n",
      "20ä¸–çºªæœ«åˆ°ä»Šæ—©å¹´é—´çš„å…¸å‹æµç¨‹åŒ…æ‹¬ä¸‰ä¸ªæ­¥éª¤:\n",
      "- æ–‡æœ¬é¢„è®­ç»ƒ(å¦‚BERTç­‰Transformerç³»åˆ—);\n",
      "- ç´¢å¼•æ„å»º(BM25/FAISS/Lucene etc.);\n",
      "- æ’åºç®—æ³•(SLAM/PQ/TensorFlow Serving).\n",
      "\n",
      "> *æ³¨æ„:* æ­¤ç±»ä½“ç³»ä¸»è¦é¢å‘å•ä¸€æ–‡æœ¬æºåœºæ™¯.\n",
      "\n",
      "---\n",
      "## \n",
      "\n",
      "äºŒã€ã€Œæ™ºèƒ½ä½“ã€å‹ RR æ‰©å±•å½¢æ€\n",
      "    \n",
      "3ï¸âƒ£ å¤šçº§ç»„åˆæ¨¡å¼(Multi-stage Recall System):\n",
      "```mermaid\n",
      "graph LR    \n",
      "A[Query] --> B{æ˜¯å¦éœ€é¢†åŸŸé€‚é…?}\n",
      "B-->|å¦|RagBase\n",
      "C[Rerank+FAQ]\n",
      "```\n",
      "\n",
      "4ï¸âƒ£ å›¾è°±åŒ–æ¨ç†(Graph-based Reasoning): å¦‚Neo4jèŠ‚ç‚¹åµŒå…¥é…åˆGNNå±‚åšå¤æ‚å…³ç³»å»ºæ¨¡.\n",
      "        \n",
      "6ï¸âƒ£ è·¨è¯­è¨€æ”¯æŒ(Cross-LINGual Search):\n",
      "\n",
      "ä½¿ç”¨m-BERT/Multilingual RoFormerä½œä¸ºç‰¹å¾æå–æ¨¡å—,\n",
      "\n",
      "7ï¸âƒ£ è§†è§‰è¾…åŠ©(Vision Transformer for Multi-modal Data), å¯ç”¨äºè§†é¢‘æ‘˜è¦æŠ½å–ä»»åŠ¡.\n",
      "\n",
      "\n",
      "ä¸‰ã€â€œè‡ªé€‚åº”â€åŠ¨æ€è°ƒæ•´æœºåˆ¶\n",
      "                \n",
      "8ï¸âƒ£ è‡ªåŠ¨è°ƒèŠ‚å‚æ•°èŒƒå›´(Auto-tuning Range Control),\n",
      "9ï¸âƒ£ åŠ¨ä½œè§„åˆ’é“¾(Action Planning Chain),\n",
      "\n",
      "å››ï¼Œâ€œå¯è§£é‡Šâ€çš„äº¤äº’åé¦ˆå¾ªç¯\n",
      "                        \n",
      "10 ğŸ§  éç›‘ç£å¼ºåŒ–å­¦ä¹ (Relational Reinforcement Learning)ï¼Œé€šè¿‡å¥–åŠ±å‡½æ•°å¼•å¯¼å¯¹è¯è·¯å¾„,\n",
      "  \n",
      "\n",
      "äº” â€œå…ƒè®¤çŸ¥â€\n",
      "11 â›³ å…ƒè®°å¿†(metamemory)-based learningï¼Œ\n",
      "  \n",
      "  \n",
      "å…­ \"è”é‚¦\"ååŒè®¡ç®—(Federated Computation)\n",
      "\n",
      "\n",
      "ä¸ƒâ€œå¾®æœåŠ¡äº‘åŸç”Ÿâ€\n",
      "\n",
      "å…«ï¼šâ€œè¾¹ç¼˜ç«¯éƒ¨ç½²â€ï¼Œé€‚ç”¨äºIoTè®¾å¤‡ä¸Šçš„è½»é‡åŒ–ç‰ˆæœ¬\n",
      "\n",
      "\n",
      "ä¹ï¼š\"æ•°å­—å­ªç”Ÿ\"\n",
      "å:\"æ¨¡æ‹Ÿä»¿çœŸ\"\n",
      "\n",
      "åä¸€.\"å› æœæ¨æ–­\"\n",
      "\n",
      "\n",
      "åäºŒ.â€œæ—¶ç©ºæ„ŸçŸ¥â€: å¯¹æ—¶é—´åºåˆ—æ•°æ®å…·æœ‰æ•æ„Ÿåº¦,\n",
      "\n",
      "\n",
      "åä¸‰.â€ç¤¾äº¤å±æ€§\": åŒ…å«è¯é¢˜çƒ­åº¦è¿½è¸ªç­‰åŠŸèƒ½,\n",
      "\n",
      "\n",
      "\n",
      "åå››ã€‚â€ä¼¦ç†åˆè§„æ§åˆ¶â€, å¼•å…¥é“å¾·çº¦æŸæ¡ä»¶;\n",
      "\n",
      "\n",
      "åäº”.â€™éšç§ä¿æŠ¤â€™,â€å·®åˆ†ç§æœ‰åŠ å¯†\";\n",
      "\n",
      "\n",
      "åå…­.'åŒºå—é“¾å­˜è¯';\n",
      "\n",
      "\n",
      "\n",
      "åä¸ƒï¼'é‡å­æœºå™¨å­¦ä¹ ';\n",
      "\n",
      "\n",
      "\n",
      "åå…«.'\"è„‘æœºæ¥å£\"' ;\n",
      "\n",
      "\n",
      "åä¹.\"'æ²‰æµ¸æ„Ÿä½“éªŒ'\"ï¼›\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "äºŒå\".è™šæ‹Ÿç°å®ç¯å¢ƒä¸­çš„è‡ªç„¶äº¤æµ\".\n",
      "\n",
      "\n",
      "\n",
      "è¿™ç§åˆ†ç±»æ ‡å‡†ä¸‹å¯ä»¥çœ‹åˆ°,RAG å·²ç»ä»æœ€åˆçš„ç®€å•é—®ç­”å·¥å…·å‘å±•ä¸ºæ¶µç›–å¤šä¸ªå­¦ç§‘é¢†åŸŸçš„ç»¼åˆæ€§AIå¹³å°ç”Ÿæ€ç³»ç»Ÿ.\n",
      "\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "æ€»ç»“æ¥è¯´:\n",
      "\n",
      "* å½“å‰æœ€å‰æ²¿çš„æŠ€æœ¯è·¯çº¿ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å…­å¤§å‘å±•æ–¹å‘*\n",
      "1. å†æ¬¡å¼ºè°ƒä¸Šè¿°å„ç‚¹å†…å®¹;\n",
      "2. æä¾›å®é™…æ¡ˆä¾‹è¯´æ˜æ¯é¡¹åˆ›æ–°çš„åº”ç”¨æ•ˆæœ;\n",
      "\n",
      "å› æ­¤å»ºè®®è¯»è€…æ ¹æ®è‡ªèº«éœ€æ±‚çµæ´»é€‰ç”¨åˆé€‚çš„æ–¹å¼å¼€å±•ç ”ç©¶å·¥ä½œ! âœï¸ğŸ“šğŸš€\n"
     ]
    }
   ],
   "source": [
    "think_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "answer_content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"think_content:\", think_content)\n",
    "print(\"answer_content:\", answer_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695c993d-0bc9-4498-8367-204b45c0124b",
   "metadata": {},
   "source": [
    "å‚è€ƒï¼š\n",
    "\n",
    "- Huggingface: [Qwen/Qwen3-4B-FP8](https://huggingface.co/Qwen/Qwen3-4B-FP8)\n",
    "- Qwen blog: [Qwen3: Think Deeper, Act Faster](https://qwenlm.github.io/blog/qwen3/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614bf86a-0baf-466f-a04b-a5586b291f89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
